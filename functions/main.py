# # === 0. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ===
# import os
# import firebase_admin as fa
# from firebase_admin import firestore as fa_firestore
# from google.cloud import firestore as gc_firestore
# from firebase_functions.firestore_fn import on_document_created# âœ… íŒŒì´ì¬ìš© Firestore íŠ¸ë¦¬ê±°
# from datetime import datetime, timezone
# import hashlib
# import json


# if not fa._apps:
#     fa.initialize_app()

# db = fa_firestore.client() 
# # === 1. ì§€ì—° ì´ˆê¸°í™”(Lazy Initialization) ìœ í‹¸ (GPT í•´ê²°ì±…) ===
# # "db = firestore.client()"ë¥¼ íŒŒì¼ ìƒë‹¨ì—ì„œ ì‹¤í–‰í•˜ì§€ ì•Šê³ ,
# # í•¨ìˆ˜ê°€ "ì‹¤ì œë¡œ" í˜¸ì¶œë  ë•Œë§Œ ì´ˆê¸°í™”í•˜ë„ë¡ í•¨.
# _app = None
# _db = None

# def get_db():
#     """ì²« í˜¸ì¶œ ë•Œë§Œ firebase_adminì„ ì´ˆê¸°í™”í•˜ê³  Firestore í´ë¼ì´ì–¸íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤."""
#     global _app, _db
#     if _db is None:
#         try:
#             # ì•±ì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
#             _app = firebase_admin.get_app()
#         except ValueError:
#             # ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ì§€ê¸ˆ ì´ˆê¸°í™”
#             _app = firebase_admin.initialize_app()
#         _db = firestore.client()
#     return _db

# # === 2. ì•ˆì •í™” íŒŒë¼ë¯¸í„° ===
# DEFAULT_MIN_STAGE_DURATION_SEC = 30  # ê¸°ë³¸ 30ì´ˆ

# def now_utc():
#     return datetime.now(timezone.utc)

# # === 3. ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ ê·œì¹™ ì´ì‹ë¶€ (ìŠ¤íƒ€í„° ë‡Œ) ===
# # (ë‚˜ì¤‘ì— JupyterLabì—ì„œ ìƒì„±ëœ ì½”ë“œë¡œ ì´ í•¨ìˆ˜ë¥¼ êµì²´í•˜ë©´ ë©ë‹ˆë‹¤)
# def predict_stage_by_tree(hr: float, motion: float, pressure: float) -> str:
#     # auto-generated from 4-class starter profiles (Awake/Light/Deep/REM)
#     if motion <= 11.5:
#         if motion <= 5.5:
#             return "Deep"
#         else:
#             return "REM"
#     else:
#         if motion <= 35.0:
#             return "Light"
#         else:
#             return "Awake"

# def stage_confidence(stage: str) -> float:
#     return {"Deep": 0.78, "REM": 0.72, "Light": 0.65, "Awake": 0.60}.get(stage, 0.55)

# def min_duration_sec_for(prev_stable_stage: str | None) -> int:
#     # v1: ëª¨ë‘ 30ì´ˆ. (v2ì—ì„œ ë‹¨ê³„ë³„ ì°¨ë“± ì ìš© ê°€ëŠ¥)
#     return DEFAULT_MIN_STAGE_DURATION_SEC

# # === 4. ëª…ë ¹ ì •ì±… ===
# def command_policy(stage: str) -> dict | None:
#     if stage == "Awake":
#         return {"type": "VIBRATE", "payload": {"intensity": 30, "durationMs": 500}, "ttlSec": 8}
#     if stage == "Light":
#         return {"type": "SET_HEIGHT", "payload": {"heightMm": 45}, "ttlSec": 10}
#     if stage == "Deep":
#         return {"type": "SET_HEIGHT", "payload": {"heightMm": 55}, "ttlSec": 10}
#     return None  # REM: ëª…ë ¹ ì—†ìŒ

# # === 5. ì„¸ì…˜ ìƒíƒœ íŠ¸ëœì­ì…˜ (í•µì‹¬ ë¡œì§) ===
# @gcf.transactional
# def _update_session_state(
#     tx: firestore.Transaction,
#     state_ref: firestore.DocumentReference,
#     *,
#     user_id: str,
#     session_id: str,
#     raw_stage: str,
#     source_ts: datetime,
#     now: datetime,
# ):
#     snap = tx.get(state_ref)
    
#     if not snap.exists:
#         # Cold start: ì„¸ì…˜ ì²« ë°ì´í„° -> ì¦‰ì‹œ í™•ì • (ì „ì´ë¡œ ê°„ì£¼)
#         new_state = {
#             "userId": user_id,
#             "sessionId": session_id,
#             "stage": raw_stage,
#             "raw_stage": raw_stage,
#             "last_change_ts": now,
#             "updated_at": now,
#             "last_source_ts": source_ts,
#         }
#         tx.set(state_ref, new_state)
#         return True, raw_stage, now  # (ì „ì´ ë°œìƒ, ì•ˆì •í™” ë‹¨ê³„, ë³€ê²½ ì‹œê°)

#     st = snap.to_dict()
#     stable_stage = st.get("stage")
#     last_change_ts = st.get("last_change_ts")
#     if isinstance(last_change_ts, str):
#         last_change_ts = datetime.fromisoformat(last_change_ts)

#     min_needed = min_duration_sec_for(stable_stage)

#     if raw_stage == stable_stage:
#         # ë³€í™” ì—†ìŒ: í•˜íŠ¸ë¹„íŠ¸ë§Œ ê°±ì‹ 
#         tx.update(state_ref, {
#             "raw_stage": raw_stage,
#             "updated_at": now,
#             "last_source_ts": source_ts,
#         })
#         return False, stable_stage, last_change_ts

#     # ë³€í™” í›„ë³´: ê²½ê³¼ì‹œê°„ ì²´í¬
#     elapsed = (now - last_change_ts).total_seconds() if last_change_ts else 10**9
#     if elapsed >= min_needed:
#         # ì „ì´ ìŠ¹ì¸
#         tx.update(state_ref, {
#             "stage": raw_stage,
#             "raw_stage": raw_stage,
#             "last_change_ts": now,
#             "updated_at": now,
#             "last_source_ts": source_ts,
#         })
#         return True, raw_stage, now
#     else:
#         # ê¹œë¹¡ì„ -> ìœ ì§€ + í•˜íŠ¸ë¹„íŠ¸
#         tx.update(state_ref, {
#             "raw_stage": raw_stage,
#             "updated_at": now,
#             "last_source_ts": source_ts,
#         })
#         return False, stable_stage, last_change_ts

# # === 6. ëª…ë ¹ ìƒì„± ìœ í‹¸ ===
# def create_command_for_stage(db, user_id, session_id, stable_stage, changed_at):
#     policy = command_policy(stable_stage)
#     if policy:
#         # ë©±ë“±í‚¤(ì¤‘ë³µ ë°©ì§€ í‚¤) ìƒì„±
#         core = json.dumps({
#             "u": user_id, "s": session_id, "stg": stable_stage,
#             "t": int(changed_at.timestamp()),
#         }, sort_keys=True).encode()
#         dkey = hashlib.sha1(core).hexdigest()[:12]
#         cmd_ref = db.collection("commands").document(dkey)
        
#         try:
#             if not cmd_ref.get().exists:
#                 cmd_ref.set({
#                     "userId": user_id,
#                     "sessionId": session_id,
#                     "type": policy["type"],
#                     "payload": policy["payload"],
#                     "status": "PENDING",
#                     "ttlSec": policy["ttlSec"],
#                     "ts": firestore.SERVER_TIMESTAMP,
#                     "dedupKey": dkey,
#                 })
#         except Exception as e:
#             print(f"ë¡œê·¸: ì»¤ë§¨ë“œ ìƒì„± ì‹¤íŒ¨ (ì¤‘ë³µ ê°€ëŠ¥ì„±): {e}")
#             pass # ì¤‘ë³µ ìƒì„± ì‹œë„ ë“±ì€ ë¬´ì‹œ

# # === 7. ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ (1ì„¸ëŒ€ íŠ¸ë¦¬ê±°) ===
# @firestore_fn.on_document_created(document="raw_data/{docId}")
# def on_new_data(event: firestore_fn.Event[firestore_fn.DocumentSnapshot]):
    
#     # âœ… 1. ì§€ì—° ì´ˆê¸°í™” ì‹¤í–‰ (GPT í•´ê²°ì±…)
#     db = get_db()

#     # 2. ë°ì´í„° ì¶”ì¶œ
#     doc = snap.to_dict() or {}
#     hr        = float(data.get("hr", 0.0))
#     motion    = float(data.get("motion", 0.0))
#     pressure  = float(data.get("pressure", 0.0))
#     user_id   = data.get("userId", "demoUser")
#     session_id= data.get("sessionId", "demoSession")
#     source_ts = data.get("ts", now_utc())
    
#     # 3. 'ë‚ ê²ƒ' ì˜ˆì¸¡
#     raw_stage = predict_stage_by_tree(hr, motion, pressure)

#     # 4. ì„¸ì…˜ ìƒíƒœ ë¬¸ì„œ(ë‹¨ì¼) ê°±ì‹  (íŠ¸ëœì­ì…˜)
#     now = now_utc()
#     state_ref = db.collection("session_state").document(f"{user_id}__{session_id}")
    
#     # íŠ¸ëœì­ì…˜ ì‹¤í–‰
#     transaction = db.transaction()
#     stage_changed, stable_stage, changed_at = _update_session_state(
#         transaction, state_ref,
#         user_id=user_id, session_id=session_id,
#         raw_stage=raw_stage, source_ts=source_ts, now=now,
#     )

#     # 5. ì „ì´ ìŠ¹ì¸ ì‹œì—ë§Œ ë¡œê·¸/ëª…ë ¹ ìƒì„±
#     if stage_changed:
#         # processed_data: "ì „ì´ ì´ë²¤íŠ¸"ë§Œ ê¸°ë¡
#         db.collection("processed_data").add({
#             "userId": user_id,
#             "sessionId": session_id,
#             "stage": stable_stage,
#             "raw_stage": raw_stage,
#             "confidence": stage_confidence(stable_stage),
#             "ts": firestore.SERVER_TIMESTAMP,
#             "changed_at": changed_at,
#             "source_ts": source_ts,
#         })
        
#         # commands: ì •ì±…ì— ë”°ë¼ 1íšŒ ìƒì„±
#         create_command_for_stage(db, user_id, session_id, stable_stage, changed_at)

#     print(f"ì„¸ì…˜ {session_id} ì²˜ë¦¬ ì™„ë£Œ: {stable_stage} (ë³€ê²½: {stage_changed})")
#     return

# === Gen2 Cloud Functions for Firebase (Python) ===
# Firestore íŠ¸ë¦¬ê±°(ë¬¸ì„œ ìƒì„±) â†’ ì„¸ì…˜ ìƒíƒœ ê°±ì‹  + ëª…ë ¹ ìƒì„±
import json
import hashlib
from datetime import datetime, timezone, timedelta

import firebase_admin
from firebase_functions import firestore_fn, options, https_fn
from firebase_admin import firestore

# google-cloud-firestore(v2) íƒ€ì…/íŠ¸ëœì­ì…˜ ë°ì½”ë ˆì´í„°ëŠ” ì—¬ê¸°ì„œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì•ˆì „í•˜ë‹¤
from google.cloud import firestore as gcf  # gcf.Transaction, gcf.DocumentReference, gcf.transactional


# ---------- lazy init ----------
_app_inited = False

def get_db() -> gcf.Client:
    global _app_inited
    if not _app_inited:
        try:
            firebase_admin.get_app()
        except ValueError:
            firebase_admin.initialize_app()
        _app_inited = True
    # Admin ì´ˆê¸°í™” ì´í›„ì—ëŠ” google-cloud-firestore í´ë¼ì´ì–¸íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì”€
    return gcf.Client()


# ---------- utility ----------
DEFAULT_MIN_STAGE_DURATION_SEC = 30

def now_utc() -> datetime:
    return datetime.now(timezone.utc)

def predict_stage_by_tree(hr: float, spo2: float, mic_level: float, pressure_level: float) -> str:
    """Auto-generated tree classifier (accuracy 100% on training set of 2220 samples)."""
    if hr <= 59.5:
        return "Deep"
    else:  # hr > 59.5
        if spo2 <= 91.9683:
            return "Apnea"
        else:  # spo2 > 91.9683
            if pressure_level <= 1493.5:
                if mic_level <= 109.5:
                    if pressure_level <= 505.0:
                        return "REM"
                    else:  # pressure_level > 505.0
                        return "Light"
                else:  # mic_level > 109.5
                    return "Snoring"
            else:  # pressure_level > 1493.5
                if pressure_level <= 2749.5:
                    return "Awake"
                else:  # pressure_level > 2749.5
                    if spo2 <= 97.1172:
                        return "Tossing"
                    else:  # spo2 > 97.1172
                        return "Tossing"

def stage_confidence(stage: str) -> float:
    return {"Deep": 0.78, "REM": 0.72, "Light": 0.65, "Awake": 0.60}.get(stage, 0.55)

def min_duration_sec_for(prev_stable_stage: str | None) -> int:
    return DEFAULT_MIN_STAGE_DURATION_SEC


def command_policy(stage: str) -> dict | None:
    # 1ìˆœìœ„: ìœ„í—˜ ì´ë²¤íŠ¸ ì²˜ë¦¬
    if stage == "Apnea":
        return {"type": "VIBRATE_STRONG", "payload": {"level": 10, "durationMs": 3000}, "ttlSec": 20}

    if stage == "Snoring":
        return {"type": "VIBRATE_GENTLY", "payload": {"level": 3, "durationMs": 500}, "ttlSec": 15}

    # 2ìˆœìœ„: ìˆ˜ë©´ ë‹¨ê³„ì— ë”°ë¥¸ ë†’ì´ ì¡°ì ˆ
    if stage == "Light":
        return {"type": "SET_HEIGHT", "payload": {"heightMm": 45}, "ttlSec": 10}

    if stage == "Deep":
        return {"type": "SET_HEIGHT", "payload": {"heightMm": 55}, "ttlSec": 10}

    # 3ìˆœìœ„: ëª…ë ¹ ì—†ìŒ (Awake, REM, Tossing ë“±)
    return None


# ---------- transactional session-state update ----------
@gcf.transactional
def _update_session_state(
    tx: gcf.Transaction,
    state_ref: gcf.DocumentReference,
    *,
    user_id: str,
    session_id: str,
    raw_stage: str,
    source_ts: datetime,
    now: datetime,
):
    # íŠ¸ëœì­ì…˜ ë°ì½”ë ˆì´í„° ëª¨ë“œì˜ ì˜¬ë°”ë¥¸ ì½ê¸° ë°©ë²•
    snap = state_ref.get(transaction=tx)
    if not snap.exists:
        # cold start
        new_state = {
            "userId": user_id,
            "sessionId": session_id,
            "stage": raw_stage,
            "raw_stage": raw_stage,
            "last_change_ts": now,
            "updated_at": now,
            "last_source_ts": source_ts,
        }
        tx.set(state_ref, new_state)
        return True, raw_stage, now

    st = snap.to_dict() or {}
    stable_stage = st.get("stage")
    last_change_ts = st.get("last_change_ts")

    # Firestore Timestamp â†’ datetime ë³´ì • (ì•ˆì „ ì²˜ë¦¬)
    if isinstance(last_change_ts, datetime):
        pass
    elif last_change_ts is not None and hasattr(last_change_ts, "to_datetime"):
        last_change_ts = last_change_ts.to_datetime().astimezone(timezone.utc)
    else:
        last_change_ts = None

    min_needed = min_duration_sec_for(stable_stage)
    elapsed = (now - last_change_ts).total_seconds() if last_change_ts else 10**9

    if raw_stage == stable_stage:
        # ë³€í™” ì—†ìŒ: rawë§Œ ê°±ì‹ 
        tx.update(state_ref, {"raw_stage": raw_stage, "updated_at": now, "last_source_ts": source_ts})
        return False, stable_stage, last_change_ts

    if elapsed >= min_needed:
        # ì „ì´ ìŠ¹ì¸
        tx.update(
            state_ref,
            {
                "stage": raw_stage,
                "raw_stage": raw_stage,
                "last_change_ts": now,
                "updated_at": now,
                "last_source_ts": source_ts,
            },
        )
        return True, raw_stage, now
    else:
        # í”Œë¦¬ì»¤(ê¹œë¹¡ì„): ì•ˆì •í™” ëŒ€ê¸°
        tx.update(state_ref, {"raw_stage": raw_stage, "updated_at": now, "last_source_ts": source_ts})
        return False, stable_stage, last_change_ts


def create_command_for_stage(db: gcf.Client, user_id: str, session_id: str, stable_stage: str, changed_at: datetime):
    policy = command_policy(stable_stage)
    if not policy:
        return  # ì •ì±…ì´ ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ

    # --- â–¼ ë””ë²„ê¹…: í˜„ì¬ ì ìš©ëœ ì •ì±… ì¶œë ¥ â–¼ ---
    print(f"[DEBUG_CMD_POLICY] policy: {policy}")
    # --- â–² ë””ë²„ê¹… ë¼ì¸ ë â–² ---

    core = json.dumps(
        {"u": user_id, "s": session_id, "stg": stable_stage, "t": int(changed_at.timestamp())},
        sort_keys=True,
    ).encode()
    dkey = hashlib.sha1(core).hexdigest()[:12]
    cmd_ref = db.collection("commands").document(dkey)

    try:
        cmd_ref.create(
            {
                "userId": user_id,
                "sessionId": session_id,
                "type": policy["type"],
                "payload": policy.get("payload", {}),
                "status": "PENDING",
                "ttlSec": policy["ttlSec"],
                "ts": gcf.SERVER_TIMESTAMP,
                "dedupKey": dkey,
            }
        )
        print(f"[ëª…ë ¹ ìƒì„± ì„±ê³µ] type: {policy['type']}, dkey: {dkey}")
    except Exception as e:
        print(f"[ëª…ë ¹ ìƒì„± ì‹¤íŒ¨] (ì•„ë§ˆë„ ì¤‘ë³µ): {e}")
        pass


# ---------- Gen2 options + Firestore trigger ----------
# í•¨ìˆ˜ ì‹¤í–‰ ë¦¬ì „(Cloud Run ìœ„ì¹˜): us-central1 (ì´ë¯¸ ì„œë¹„ìŠ¤ê°€ ê±°ê¸°ì— ìˆìŒ)
options.set_global_options(region="asia-northeast3")

# ì´ë²¤íŠ¸ êµ¬ë… ë¦¬ì „(Eventarc/Firestore ìœ„ì¹˜): asia-northeast3 (í”„ë¡œì íŠ¸ Firestoreê°€ ì„œìš¸)
@firestore_fn.on_document_created(document="raw_data/{docId}", region="asia-northeast3")
def on_new_data(event: firestore_fn.Event[firestore_fn.DocumentSnapshot | None]):
    db = get_db()

    if event.data is None:
        print("no event data; skip")
        return

    data = event.data.to_dict() or {}
    hr = float(data.get("hr", 0.0))
    spo2 = float(data.get("spo2", 98.0))
    mic_level = float(data.get("mic_level", data.get("motion", 0.0)))
    pressure_level = float(data.get("pressure_level", data.get("pressure", 0.0)))
    user_id = data.get("userId", "demoUser")
    session_id = data.get("sessionId", "demoSession")

    # tsëŠ” ì—¬ëŸ¬ í˜•íƒœë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆìŒ: Firestore Timestamp, ISO ë¬¸ìì—´, epoch(ms/sec), dict {seconds,nanos}
    source_ts_raw = data.get("ts")
    if source_ts_raw is None:
        source_ts = now_utc()
    elif isinstance(source_ts_raw, datetime):
        source_ts = source_ts_raw.astimezone(timezone.utc)
    else:
        try:
            # Firestore Timestamp íƒ€ì… ì²˜ë¦¬
            try:
                from google.cloud.firestore_v1 import Timestamp as FsTimestamp  # type: ignore
            except Exception:
                FsTimestamp = None  # type: ignore

            if FsTimestamp is not None and isinstance(source_ts_raw, FsTimestamp):
                source_ts = source_ts_raw.to_datetime().astimezone(timezone.utc)
            elif isinstance(source_ts_raw, dict) and "seconds" in source_ts_raw:
                source_ts = datetime.fromtimestamp(source_ts_raw["seconds"], tz=timezone.utc)
            elif isinstance(source_ts_raw, (int, float)):
                # ê°’ì´ ë§¤ìš° í¬ë©´ msë¡œ ê°„ì£¼
                divisor = 1000.0 if source_ts_raw > 1e12 else 1.0
                source_ts = datetime.fromtimestamp(source_ts_raw / divisor, tz=timezone.utc)
            elif isinstance(source_ts_raw, str):
                try:
                    parsed = datetime.fromisoformat(source_ts_raw)
                    source_ts = parsed.astimezone(timezone.utc) if parsed.tzinfo else parsed.replace(tzinfo=timezone.utc)
                except Exception:
                    source_ts = now_utc()
            else:
                source_ts = now_utc()
        except Exception:
            source_ts = now_utc()

    raw_stage = predict_stage_by_tree(hr, spo2, mic_level, pressure_level)

    now = now_utc()
    state_ref = db.collection("session_state").document(f"{user_id}__{session_id}")

    try:
        tx = db.transaction()
        stage_changed, stable_stage, changed_at = _update_session_state(
            tx,
            state_ref,
            user_id=user_id,
            session_id=session_id,
            raw_stage=raw_stage,
            source_ts=source_ts,
            now=now,
        )
    except Exception as e:
        print(f"[state] transaction failed: {e}")
        return

    if stage_changed:
        db.collection("processed_data").add(
            {
                "userId": user_id,
                "sessionId": session_id,
                "stage": stable_stage,
                "raw_stage": raw_stage,
                "confidence": stage_confidence(stable_stage),
                "ts": gcf.SERVER_TIMESTAMP,
                "changed_at": changed_at,
                "source_ts": source_ts,
            }
        )
        create_command_for_stage(db, user_id, session_id, stable_stage, changed_at)

    print(f"[session {session_id}] stable={stable_stage}, changed={stage_changed}")


# ========================================
# âœ¨ Eë‹¨ê³„: ìˆ˜ë©´ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ (ìˆ˜ì •!)
# ========================================

@https_fn.on_call()
def calculate_sleep_score(req: https_fn.CallableRequest):
    """
    íŠ¹ì • ì„¸ì…˜ì˜ ìˆ˜ë©´ ì ìˆ˜ë¥¼ ê³„ì‚°
    
    ìš”ì²­ íŒŒë¼ë¯¸í„°:
    - session_id: ì„¸ì…˜ ID (í•„ìˆ˜)
    - user_id: ì‚¬ìš©ì ID (ì„ íƒ, ì—†ìœ¼ë©´ ì„¸ì…˜ì—ì„œ ì¶”ì¶œ)
    
    ë°˜í™˜:
    - total_score: ì´ì  (100ì  ë§Œì )
    - breakdown: ì„¸ë¶€ ì ìˆ˜
    - summary: ìˆ˜ë©´ ìš”ì•½
    - message: í‰ê°€ ë©”ì‹œì§€
    """
    db = get_db()
    
    # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    session_id = req.data.get("session_id")
    if not session_id:
        raise https_fn.HttpsError("invalid-argument", "session_id is required")
    
    user_id = req.data.get("user_id")
    
    print(f"[ìˆ˜ë©´ ì ìˆ˜ ê³„ì‚° ì‹œì‘] session_id: {session_id}")
    
    try:
        # processed_dataì—ì„œ ì„¸ì…˜ ë°ì´í„° ì¡°íšŒ
        processed_docs = db.collection("processed_data")\
            .where("sessionId", "==", session_id)\
            .order_by("changed_at", direction=firestore.Query.ASCENDING)\
            .stream()
        
        # ë°ì´í„° ìˆ˜ì§‘
        stages_data = []
        for doc in processed_docs:
            data = doc.to_dict()
            stages_data.append(data)
            
            # user_id ì¶”ì¶œ (íŒŒë¼ë¯¸í„°ë¡œ ì•ˆ ë„˜ì–´ì™”ì„ ë•Œ)
            if not user_id:
                user_id = data.get("userId")
        
        if not stages_data:
            return {
                "error": "No data found",
                "session_id": session_id,
                "total_score": 0,
                "message": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        # 1. ìˆ˜ë©´ ì‹œê°„ ê³„ì‚°
        first_ts = stages_data[0]["changed_at"]
        last_ts = stages_data[-1]["changed_at"]
        
        # Timestamp ë³€í™˜
        if hasattr(first_ts, "to_datetime"):
            first_ts = first_ts.to_datetime()
        if hasattr(last_ts, "to_datetime"):
            last_ts = last_ts.to_datetime()
        
        total_duration_sec = (last_ts - first_ts).total_seconds()
        total_duration_hours = total_duration_sec / 3600
        
        # 2. ë‹¨ê³„ë³„ ì‹œê°„ ê³„ì‚°
        stage_durations = {"Deep": 0, "Light": 0, "REM": 0, "Awake": 0, "Apnea": 0, "Snoring": 0}
        
        for i in range(len(stages_data) - 1):
            current = stages_data[i]
            next_item = stages_data[i + 1]
            
            current_ts = current["changed_at"]
            next_ts = next_item["changed_at"]
            
            if hasattr(current_ts, "to_datetime"):
                current_ts = current_ts.to_datetime()
            if hasattr(next_ts, "to_datetime"):
                next_ts = next_ts.to_datetime()
            
            duration = (next_ts - current_ts).total_seconds()
            stage = current.get("stage", "Unknown")
            
            if stage in stage_durations:
                stage_durations[stage] += duration
        
        # 3. ì ìˆ˜ ê³„ì‚°
        
        # 3-1. ìˆ˜ë©´ ì‹œê°„ ì ìˆ˜ (40ì ) - 7~9ì‹œê°„ì´ ì´ìƒì 
        if 7 <= total_duration_hours <= 9:
            duration_score = 40
        elif 6 <= total_duration_hours < 7:
            duration_score = 30
        elif 9 < total_duration_hours <= 10:
            duration_score = 35
        elif 5 <= total_duration_hours < 6:
            duration_score = 20
        else:
            duration_score = 10
        
        # 3-2. ê¹Šì€ ìˆ˜ë©´ ì ìˆ˜ (25ì ) - ì „ì²´ì˜ 15~25%ê°€ ì´ìƒì 
        deep_ratio = stage_durations["Deep"] / total_duration_sec if total_duration_sec > 0 else 0
        if 0.15 <= deep_ratio <= 0.25:
            deep_score = 25
        elif 0.10 <= deep_ratio < 0.15:
            deep_score = 20
        elif 0.25 < deep_ratio <= 0.30:
            deep_score = 20
        else:
            deep_score = 10
        
        # 3-3. REM ìˆ˜ë©´ ì ìˆ˜ (20ì ) - ì „ì²´ì˜ 20~25%ê°€ ì´ìƒì 
        rem_ratio = stage_durations["REM"] / total_duration_sec if total_duration_sec > 0 else 0
        if 0.20 <= rem_ratio <= 0.25:
            rem_score = 20
        elif 0.15 <= rem_ratio < 0.20:
            rem_score = 15
        elif 0.25 < rem_ratio <= 0.30:
            rem_score = 15
        else:
            rem_score = 8
        
        # 3-4. ìˆ˜ë©´ íš¨ìœ¨ ì ìˆ˜ (15ì ) - Awake ì‹œê°„ì´ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
        awake_ratio = stage_durations["Awake"] / total_duration_sec if total_duration_sec > 0 else 0
        if awake_ratio < 0.05:
            efficiency_score = 15
        elif awake_ratio < 0.10:
            efficiency_score = 12
        elif awake_ratio < 0.15:
            efficiency_score = 8
        else:
            efficiency_score = 3
        
        # ì´ì 
        total_score = duration_score + deep_score + rem_score + efficiency_score
        
        # 4. í‰ê°€ ë©”ì‹œì§€
        if total_score >= 90:
            message = "í›Œë¥­í•œ ìˆ˜ë©´ì´ì—ˆìŠµë‹ˆë‹¤! ğŸŒŸ"
            grade = "S"
        elif total_score >= 80:
            message = "ì¢‹ì€ ìˆ˜ë©´ì…ë‹ˆë‹¤ ğŸ˜Š"
            grade = "A"
        elif total_score >= 70:
            message = "ì–‘í˜¸í•œ ìˆ˜ë©´ì…ë‹ˆë‹¤ ğŸ‘"
            grade = "B"
        elif total_score >= 60:
            message = "ìˆ˜ë©´ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ğŸ˜"
            grade = "C"
        else:
            message = "ìˆ˜ë©´ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤ âš ï¸"
            grade = "D"
        
        # âœ… 5. í˜„ì¬ ì‹œê°„ (ISO ë¬¸ìì—´)
        current_time = now_utc()
        
        # âœ… 6. ê²°ê³¼ ë°ì´í„° (ë°˜í™˜ìš© - JSON ì§ë ¬í™” ê°€ëŠ¥)
        report_data = {
            "userId": user_id,
            "sessionId": session_id,
            "created_at": current_time.isoformat(),  # âœ… ISO ë¬¸ìì—´
            
            # ì ìˆ˜
            "total_score": round(total_score),
            "grade": grade,
            "message": message,
            
            # ì„¸ë¶€ ì ìˆ˜
            "breakdown": {
                "duration_score": duration_score,
                "deep_score": deep_score,
                "rem_score": rem_score,
                "efficiency_score": efficiency_score
            },
            
            # ìˆ˜ë©´ ìš”ì•½
            "summary": {
                "total_duration_hours": round(total_duration_hours, 2),
                "deep_sleep_hours": round(stage_durations["Deep"] / 3600, 2),
                "rem_sleep_hours": round(stage_durations["REM"] / 3600, 2),
                "light_sleep_hours": round(stage_durations["Light"] / 3600, 2),
                "awake_hours": round(stage_durations["Awake"] / 3600, 2),
                
                "deep_ratio": round(deep_ratio * 100, 1),
                "rem_ratio": round(rem_ratio * 100, 1),
                "awake_ratio": round(awake_ratio * 100, 1),
                
                "apnea_count": sum(1 for s in stages_data if s.get("stage") == "Apnea"),
                "snoring_duration": round(stage_durations["Snoring"] / 60, 1)  # ë¶„ ë‹¨ìœ„
            }
        }
        
        # âœ… 7. Firestoreì— ì €ì¥ (SERVER_TIMESTAMP ì‚¬ìš©)
        db.collection("sleep_reports").document(session_id).set({
            **report_data,
            "created_at": gcf.SERVER_TIMESTAMP  # Firestoreìš©ìœ¼ë¡œë§Œ
        })
        
        print(f"[ìˆ˜ë©´ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ] session: {session_id}, score: {total_score}")
        
        # âœ… 8. ë°˜í™˜ (ISO ë¬¸ìì—´ í¬í•¨)
        return report_data
        
    except Exception as e:
        print(f"[ìˆ˜ë©´ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜] {e}")
        raise https_fn.HttpsError("internal", f"Score calculation failed: {str(e)}")


# ========================================
# âœ¨ Eë‹¨ê³„: ì£¼ê°„ í†µê³„ ê³„ì‚°
# ========================================

@https_fn.on_call()
def calculate_weekly_stats(req: https_fn.CallableRequest):
    """
    ì‚¬ìš©ìì˜ ì£¼ê°„ ìˆ˜ë©´ í†µê³„ ê³„ì‚°
    
    ìš”ì²­ íŒŒë¼ë¯¸í„°:
    - user_id: ì‚¬ìš©ì ID (í•„ìˆ˜)
    - week_start: ì£¼ ì‹œì‘ì¼ (ì„ íƒ, ISO í˜•ì‹, ê¸°ë³¸: 7ì¼ ì „)
    
    ë°˜í™˜:
    - ì£¼ê°„ í‰ê·  ì ìˆ˜, ìˆ˜ë©´ ì‹œê°„, íŠ¸ë Œë“œ ë“±
    """
    db = get_db()
    
    user_id = req.data.get("user_id")
    if not user_id:
        raise https_fn.HttpsError("invalid-argument", "user_id is required")
    
    # ì£¼ ì‹œì‘ì¼ íŒŒì‹±
    week_start_str = req.data.get("week_start")
    if week_start_str:
        try:
            week_start = datetime.fromisoformat(week_start_str).replace(tzinfo=timezone.utc)
        except:
            week_start = datetime.now(timezone.utc) - timedelta(days=7)
    else:
        week_start = datetime.now(timezone.utc) - timedelta(days=7)
    
    print(f"[ì£¼ê°„ í†µê³„ ê³„ì‚°] user: {user_id}, from: {week_start}")
    
    try:
        # í•´ë‹¹ ê¸°ê°„ì˜ ë¦¬í¬íŠ¸ ì¡°íšŒ
        reports = db.collection("sleep_reports")\
            .where("userId", "==", user_id)\
            .where("created_at", ">=", week_start)\
            .stream()
        
        report_list = [doc.to_dict() for doc in reports]
        
        if not report_list:
            return {
                "user_id": user_id,
                "week_start": week_start.isoformat(),
                "report_count": 0,
                "message": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        # í†µê³„ ê³„ì‚°
        total_scores = [r["total_score"] for r in report_list]
        sleep_hours = [r["summary"]["total_duration_hours"] for r in report_list]
        
        avg_score = sum(total_scores) / len(total_scores)
        avg_sleep = sum(sleep_hours) / len(sleep_hours)
        
        # ìµœê³ /ìµœì•…ì¼
        best_day = max(report_list, key=lambda x: x["total_score"])
        worst_day = min(report_list, key=lambda x: x["total_score"])
        
        # íŠ¸ë Œë“œ (ê°„ë‹¨ ë²„ì „: ì „ë°˜ë¶€ vs í›„ë°˜ë¶€)
        mid = len(total_scores) // 2
        if mid > 0:
            first_half_avg = sum(total_scores[:mid]) / mid
            second_half_avg = sum(total_scores[mid:]) / (len(total_scores) - mid)
            
            if second_half_avg > first_half_avg + 5:
                trend = "improving"
            elif second_half_avg < first_half_avg - 5:
                trend = "declining"
            else:
                trend = "stable"
        else:
            trend = "insufficient_data"
        
        result = {
            "user_id": user_id,
            "week_start": week_start.isoformat(),
            "report_count": len(report_list),
            
            "averages": {
                "score": round(avg_score, 1),
                "sleep_hours": round(avg_sleep, 2)
            },
            
            "best_day": {
                "session_id": best_day["sessionId"],
                "score": best_day["total_score"],
                "sleep_hours": best_day["summary"]["total_duration_hours"]
            },
            
            "worst_day": {
                "session_id": worst_day["sessionId"],
                "score": worst_day["total_score"],
                "sleep_hours": worst_day["summary"]["total_duration_hours"]
            },
            
            "trend": trend
        }
        
        print(f"[ì£¼ê°„ í†µê³„ ì™„ë£Œ] {len(report_list)}ê°œ ë¦¬í¬íŠ¸, í‰ê·  ì ìˆ˜: {avg_score:.1f}")
        
        return result
        
    except Exception as e:
        print(f"[ì£¼ê°„ í†µê³„ ì˜¤ë¥˜] {e}")
        raise https_fn.HttpsError("internal", f"Stats calculation failed: {str(e)}")
    
    # ========================================
# âœ¨ Phase 3: ì¸ì‚¬ì´íŠ¸ ìƒì„±
# ========================================

@https_fn.on_call()
def generate_sleep_insights(req: https_fn.CallableRequest):
    """
    ìˆ˜ë©´ ë¦¬í¬íŠ¸ ê¸°ë°˜ ë§ì¶¤í˜• ì¸ì‚¬ì´íŠ¸ ë° ê°œì„  ì œì•ˆ ìƒì„±
    
    ìš”ì²­ íŒŒë¼ë¯¸í„°:
    - session_id: ì„¸ì…˜ ID (í•„ìˆ˜)
    
    ë°˜í™˜:
    - insights: ì¸ì‚¬ì´íŠ¸ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ)
    - overall: ì¢…í•© í‰ê°€
    - action_plan: ì‹¤í–‰ ê³„íš
    """
    db = get_db()
    
    session_id = req.data.get("session_id")
    if not session_id:
        raise https_fn.HttpsError("invalid-argument", "session_id is required")
    
    print(f"[ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘] session: {session_id}")
    
    try:
        # ë¦¬í¬íŠ¸ ê°€ì ¸ì˜¤ê¸°
        report_doc = db.collection("sleep_reports").document(session_id).get()
        
        if not report_doc.exists:
            raise https_fn.HttpsError("not-found", f"Report not found for session: {session_id}")
        
        report = report_doc.to_dict()
        
        # ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘
        insights = []
        
        # 1. ìˆ˜ë©´ ì‹œê°„ ë¶„ì„
        sleep_hours = report["summary"]["total_duration_hours"]
        
        if sleep_hours < 5:
            insights.append({
                "type": "critical",
                "category": "duration",
                "title": "ì‹¬ê°í•œ ìˆ˜ë©´ ë¶€ì¡±",
                "message": f"í˜„ì¬ {sleep_hours:.1f}ì‹œê°„ìœ¼ë¡œ ê±´ê°•ì— ìœ„í—˜í•  ìˆ˜ ìˆì–´ìš”",
                "priority": 1,
                "impact": "ê±´ê°•, ì§‘ì¤‘ë ¥, ë©´ì—­ë ¥",
                "actions": [
                    "ì˜¤ëŠ˜ ë°¤ ìµœì†Œ 7ì‹œê°„ ìˆ˜ë©´ ëª©í‘œ ì„¤ì •",
                    "ì·¨ì¹¨ ì‹œê°„ 2ì‹œê°„ ì•ë‹¹ê¸°ê¸°",
                    "ë‚®ì  20ë¶„ ì´ë‚´ë¡œ ì œí•œ"
                ]
            })
        elif sleep_hours < 6:
            insights.append({
                "type": "warning",
                "category": "duration",
                "title": "ìˆ˜ë©´ ì‹œê°„ ë¶€ì¡±",
                "message": f"í˜„ì¬ {sleep_hours:.1f}ì‹œê°„ìœ¼ë¡œ ê¶Œì¥(7-9ì‹œê°„)ë³´ë‹¤ ë¶€ì¡±í•´ìš”",
                "priority": 2,
                "impact": "í”¼ë¡œ ëˆ„ì , ì—…ë¬´ íš¨ìœ¨ ì €í•˜",
                "actions": [
                    "ì·¨ì¹¨ ì‹œê°„ì„ 1ì‹œê°„ ì•ë‹¹ê¸°ê¸°",
                    "ê¸°ìƒ ì•ŒëŒ 30ë¶„ ëŠ¦ì¶”ê¸°",
                    "ì£¼ë§ì— ë³´ì¶© ìˆ˜ë©´"
                ]
            })
        elif sleep_hours > 10:
            insights.append({
                "type": "info",
                "category": "duration",
                "title": "ê³¼ë„í•œ ìˆ˜ë©´",
                "message": f"{sleep_hours:.1f}ì‹œê°„ì€ ê¶Œì¥(7-9ì‹œê°„)ë³´ë‹¤ ë§ì•„ìš”",
                "priority": 3,
                "impact": "ë‚® ë™ì•ˆ ì¡¸ë¦¼, ìš´ë™ ë¶€ì¡±",
                "actions": [
                    "ê·œì¹™ì ì¸ ê¸°ìƒ ì‹œê°„ ì„¤ì •",
                    "ë‚® í™œë™ëŸ‰ ëŠ˜ë¦¬ê¸°",
                    "ì¹´í˜ì¸ ì„­ì·¨ ì¤„ì´ê¸°"
                ]
            })
        
        # 2. ê¹Šì€ ìˆ˜ë©´ ë¶„ì„
        deep_ratio = report["summary"]["deep_ratio"]
        deep_hours = report["summary"]["deep_sleep_hours"]
        
        if deep_ratio < 5:
            insights.append({
                "type": "critical",
                "category": "quality",
                "title": "ê¹Šì€ ìˆ˜ë©´ ì‹¬ê° ë¶€ì¡±",
                "message": f"ê¹Šì€ ìˆ˜ë©´ì´ {deep_ratio:.1f}%ë¡œ ë§¤ìš° ë¶€ì¡±í•´ìš” (ê¶Œì¥: 15-25%)",
                "priority": 1,
                "impact": "íšŒë³µë ¥, ì„±ì¥í˜¸ë¥´ëª¬, ë©´ì—­ë ¥",
                "actions": [
                    "ì €ë… 6ì‹œ ì´í›„ ì¹´í˜ì¸ ê¸ˆì§€",
                    "ì˜¤í›„ 3-5ì‹œì— 30ë¶„ ìœ ì‚°ì†Œ ìš´ë™",
                    "ì·¨ì¹¨ 2ì‹œê°„ ì „ ë”°ëœ»í•œ ìƒ¤ì›Œ",
                    "ì¹¨ì‹¤ ì˜¨ë„ 18-20ë„ ìœ ì§€"
                ]
            })
        elif deep_ratio < 10:
            insights.append({
                "type": "warning",
                "category": "quality",
                "title": "ê¹Šì€ ìˆ˜ë©´ ë¶€ì¡±",
                "message": f"ê¹Šì€ ìˆ˜ë©´ì´ {deep_ratio:.1f}% ({deep_hours:.1f}ì‹œê°„)ë¡œ ë¶€ì¡±í•´ìš”",
                "priority": 2,
                "impact": "í”¼ë¡œ íšŒë³µ, ê¸°ì–µë ¥",
                "actions": [
                    "ë‚®ì— 20-30ë¶„ ê°€ë²¼ìš´ ìš´ë™",
                    "ì €ë… ì‹ì‚¬ ì·¨ì¹¨ 3ì‹œê°„ ì „",
                    "ì·¨ì¹¨ ì „ ìŠ¤íŠ¸ë ˆì¹­ 10ë¶„"
                ]
            })
        
        # 3. REM ìˆ˜ë©´ ë¶„ì„
        rem_ratio = report["summary"]["rem_ratio"]
        rem_hours = report["summary"]["rem_sleep_hours"]
        
        if rem_ratio < 10:
            insights.append({
                "type": "warning",
                "category": "quality",
                "title": "REM ìˆ˜ë©´ ë¶€ì¡±",
                "message": f"REM ìˆ˜ë©´ì´ {rem_ratio:.1f}% ({rem_hours:.1f}ì‹œê°„)ë¡œ ë¶€ì¡±í•´ìš” (ê¶Œì¥: 20-25%)",
                "priority": 2,
                "impact": "í•™ìŠµ, ê¸°ì–µë ¥, ê°ì • ì¡°ì ˆ",
                "actions": [
                    "ê·œì¹™ì ì¸ ìˆ˜ë©´ ìŠ¤ì¼€ì¤„ ìœ ì§€",
                    "ì•Œì½”ì˜¬ ì„­ì·¨ ì¤„ì´ê¸°",
                    "ì¶©ë¶„í•œ ì´ ìˆ˜ë©´ ì‹œê°„ í™•ë³´"
                ]
            })
        
        # 4. ìˆ˜ë©´ íš¨ìœ¨ ë¶„ì„
        awake_ratio = report["summary"]["awake_ratio"]
        awake_hours = report["summary"]["awake_hours"]
        
        if awake_ratio > 20:
            insights.append({
                "type": "warning",
                "category": "efficiency",
                "title": "ìˆ˜ë©´ íš¨ìœ¨ ë§¤ìš° ë‚®ìŒ",
                "message": f"ìˆ˜ë©´ ì¤‘ {awake_ratio:.1f}% ({awake_hours:.1f}ì‹œê°„) ê¹¨ì–´ìˆì—ˆì–´ìš”",
                "priority": 2,
                "impact": "ìˆ˜ë©´ì˜ ì§ˆ, ë‚® í”¼ë¡œ",
                "actions": [
                    "ì¹¨ì‹¤ì„ ì™„ì „íˆ ì–´ë‘¡ê²Œ",
                    "ì†ŒìŒ ì°¨ë‹¨ (ê·€ë§ˆê°œ ì‚¬ìš©)",
                    "ì·¨ì¹¨ 1ì‹œê°„ ì „ ìŠ¤ë§ˆíŠ¸í°/TV ë„ê¸°",
                    "ì¹¨ëŒ€ëŠ” ìˆ˜ë©´ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©"
                ]
            })
        elif awake_ratio > 10:
            insights.append({
                "type": "info",
                "category": "efficiency",
                "title": "ìˆ˜ë©´ íš¨ìœ¨ ê°œì„  í•„ìš”",
                "message": f"ìˆ˜ë©´ ì¤‘ {awake_ratio:.1f}% ê¹¨ì–´ìˆì—ˆì–´ìš” (ê¶Œì¥: 5% ì´í•˜)",
                "priority": 3,
                "impact": "ìˆ˜ë©´ì˜ ì§ˆ",
                "actions": [
                    "ì·¨ì¹¨ í™˜ê²½ ì ê²€ (ì˜¨ë„, ì†ŒìŒ, ë¹›)",
                    "ê·œì¹™ì ì¸ ì·¨ì¹¨ ë£¨í‹´ ë§Œë“¤ê¸°"
                ]
            })
        
        # 5. ë¬´í˜¸í¡ ê²½ê³ 
        apnea_count = report["summary"]["apnea_count"]
        
        if apnea_count > 15:
            insights.append({
                "type": "critical",
                "category": "health",
                "title": "âš ï¸ ìˆ˜ë©´ ë¬´í˜¸í¡ ìœ„í—˜",
                "message": f"ìˆ˜ë©´ ì¤‘ {apnea_count}íšŒ ë¬´í˜¸í¡ì´ ê°ì§€ëì–´ìš”",
                "priority": 1,
                "impact": "ì‹¬í˜ˆê´€ ê±´ê°•, ë‡Œ ì‚°ì†Œ ê³µê¸‰",
                "actions": [
                    "ì¦‰ì‹œ ìˆ˜ë©´ ì „ë¬¸ì˜ ìƒë‹´ ì˜ˆì•½",
                    "ìˆ˜ë©´ë‹¤ì›ê²€ì‚¬ ê¶Œì¥",
                    "ë‹¹ë¶„ê°„ ì˜†ìœ¼ë¡œ ìê¸°"
                ]
            })
        elif apnea_count > 5:
            insights.append({
                "type": "warning",
                "category": "health",
                "title": "ë¬´í˜¸í¡ ê°ì§€",
                "message": f"ìˆ˜ë©´ ì¤‘ {apnea_count}íšŒ ë¬´í˜¸í¡ì´ ê°ì§€ëì–´ìš”",
                "priority": 2,
                "impact": "ìˆ˜ë©´ì˜ ì§ˆ, í”¼ë¡œ",
                "actions": [
                    "ì²´ì¤‘ ê´€ë¦¬ (BMI ì •ìƒ ë²”ìœ„)",
                    "ê¸ˆì—° ë° ìŒì£¼ ì œí•œ",
                    "ì˜†ìœ¼ë¡œ ìëŠ” ìŠµê´€ ë“¤ì´ê¸°",
                    "2ì£¼ í›„ì—ë„ ì§€ì†ë˜ë©´ ë³‘ì› ìƒë‹´"
                ]
            })
        
        # 6. ì½”ê³¨ì´ ë¶„ì„
        snoring_duration = report["summary"]["snoring_duration"]
        
        if snoring_duration > 60:
            insights.append({
                "type": "warning",
                "category": "health",
                "title": "ì‹¬í•œ ì½”ê³¨ì´ ê°ì§€",
                "message": f"ìˆ˜ë©´ ì¤‘ {snoring_duration:.0f}ë¶„ ë™ì•ˆ ì½”ë¥¼ ê³¨ì•˜ì–´ìš”",
                "priority": 2,
                "impact": "ìˆ˜ë©´ì˜ ì§ˆ, ì£¼ë³€ ì‚¬ëŒ",
                "actions": [
                    "ì˜†ìœ¼ë¡œ ìê¸° (ë“± ë°›ì¹¨ ë² ê°œ ì‚¬ìš©)",
                    "ë¹„ê°• í™•ì¥ ìŠ¤íŠ¸ë¦½ ì‚¬ìš©",
                    "ì²´ì¤‘ ê°ëŸ‰ (ê³¼ì²´ì¤‘ì¸ ê²½ìš°)",
                    "ì•Œì½”ì˜¬ ì„­ì·¨ ì¤„ì´ê¸°"
                ]
            })
        elif snoring_duration > 30:
            insights.append({
                "type": "info",
                "category": "health",
                "title": "ì½”ê³¨ì´ ê°ì§€",
                "message": f"ìˆ˜ë©´ ì¤‘ {snoring_duration:.0f}ë¶„ ë™ì•ˆ ì½”ë¥¼ ê³¨ì•˜ì–´ìš”",
                "priority": 3,
                "impact": "ìˆ˜ë©´ì˜ ì§ˆ",
                "actions": [
                    "ì˜†ìœ¼ë¡œ ìëŠ” ìŠµê´€",
                    "ë² ê°œ ë†’ì´ ì¡°ì ˆ"
                ]
            })
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
        insights.sort(key=lambda x: x["priority"])
        
        # 7. ì¢…í•© í‰ê°€
        score = report["total_score"]
        
        if score >= 90:
            overall = {
                "grade": "S",
                "message": "ì™„ë²½í•œ ìˆ˜ë©´ì…ë‹ˆë‹¤! ğŸŒŸ",
                "summary": "ëª¨ë“  ì§€í‘œê°€ ì´ìƒì ì…ë‹ˆë‹¤. í˜„ì¬ ìˆ˜ë©´ ìŠµê´€ì„ ê¾¸ì¤€íˆ ìœ ì§€í•˜ì„¸ìš”.",
                "emoji": "ğŸŒŸ"
            }
        elif score >= 80:
            overall = {
                "grade": "A",
                "message": "ì¢‹ì€ ìˆ˜ë©´ì…ë‹ˆë‹¤ ğŸ˜Š",
                "summary": "ëŒ€ë¶€ë¶„ì˜ ì§€í‘œê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ëª‡ ê°€ì§€ë§Œ ê°œì„ í•˜ë©´ ì™„ë²½í•´ì§ˆ ìˆ˜ ìˆì–´ìš”.",
                "emoji": "ğŸ˜Š"
            }
        elif score >= 70:
            overall = {
                "grade": "B",
                "message": "ì–‘í˜¸í•œ ìˆ˜ë©´ì…ë‹ˆë‹¤ ğŸ‘",
                "summary": "ê¸°ë³¸ì€ ê°–ì·„ì§€ë§Œ ê°œì„ í•  ë¶€ë¶„ì´ ìˆì–´ìš”. ì•„ë˜ ì¡°ì–¸ì„ ì°¸ê³ í•˜ì„¸ìš”.",
                "emoji": "ğŸ‘"
            }
        elif score >= 60:
            overall = {
                "grade": "C",
                "message": "ìˆ˜ë©´ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤ ğŸ˜",
                "summary": "ì—¬ëŸ¬ ì§€í‘œì—ì„œ ê°œì„ ì´ í•„ìš”í•´ìš”. ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒë¶€í„° ì‹¤ì²œí•˜ì„¸ìš”.",
                "emoji": "ğŸ˜"
            }
        else:
            overall = {
                "grade": "D",
                "message": "ìˆ˜ë©´ì— ì ê·¹ì ì¸ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤ âš ï¸",
                "summary": "ê±´ê°•ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ì‹¬ê°í•œ ë¬¸ì œë“¤ì´ ìˆì–´ìš”. ì¦‰ì‹œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "emoji": "âš ï¸"
            }
        
        # 8. ì˜¤ëŠ˜ì˜ ì‹¤í–‰ ê³„íš (ìš°ì„ ìˆœìœ„ Top 3)
        action_plan = {
            "today": [],
            "this_week": [],
            "long_term": []
        }
        
        # ìš°ì„ ìˆœìœ„ 1 (critical) - ì˜¤ëŠ˜ ë‹¹ì¥
        critical_insights = [i for i in insights if i["type"] == "critical"]
        for insight in critical_insights[:2]:  # ìµœëŒ€ 2ê°œ
            action_plan["today"].extend(insight["actions"][:2])
        
        # ìš°ì„ ìˆœìœ„ 2 (warning) - ì´ë²ˆ ì£¼
        warning_insights = [i for i in insights if i["type"] == "warning"]
        for insight in warning_insights[:2]:  # ìµœëŒ€ 2ê°œ
            action_plan["this_week"].extend(insight["actions"][:1])
        
        # ìš°ì„ ìˆœìœ„ 3 (info) - ì¥ê¸°
        info_insights = [i for i in insights if i["type"] == "info"]
        for insight in info_insights[:1]:  # ìµœëŒ€ 1ê°œ
            action_plan["long_term"].extend(insight["actions"][:1])
        
        result = {
            "session_id": session_id,
            "score": score,
            "overall": overall,
            "insights": insights,
            "insights_count": len(insights),
            "action_plan": action_plan,
            "generated_at": now_utc().isoformat()
        }
        
        # Firestoreì— ì €ì¥
        db.collection("sleep_insights").document(session_id).set(result)
        
        print(f"[ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ] session: {session_id}, insights: {len(insights)}")
        
        return result
        
    except https_fn.HttpsError:
        raise
    except Exception as e:
        print(f"[ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜] {e}")
        raise https_fn.HttpsError("internal", f"Insights generation failed: {str(e)}")
    
# ========================================
# âœ¨ Phase 4: ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„
# ========================================

@https_fn.on_call()
def calculate_monthly_trends(req: https_fn.CallableRequest):
    """
    ìµœê·¼ 30ì¼ ìˆ˜ë©´ íŒ¨í„´ ë° íŠ¸ë Œë“œ ë¶„ì„
    
    ìš”ì²­ íŒŒë¼ë¯¸í„°:
    - user_id: ì‚¬ìš©ì ID (í•„ìˆ˜)
    - days: ë¶„ì„ ê¸°ê°„ (ì„ íƒ, ê¸°ë³¸: 30)
    
    ë°˜í™˜:
    - ì›”ê°„ í‰ê·  í†µê³„
    - ì£¼ì¤‘/ì£¼ë§ ë¹„êµ
    - ìš”ì¼ë³„ ë¶„ì„
    - ê°œì„  ì¶”ì„¸
    """
    db = get_db()
    
    user_id = req.data.get("user_id")
    if not user_id:
        raise https_fn.HttpsError("invalid-argument", "user_id is required")
    
    days = req.data.get("days", 30)
    start_date = datetime.now(timezone.utc) - timedelta(days=days)
    
    print(f"[ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„] user: {user_id}, days: {days}")
    
    try:
        # ê¸°ê°„ ë‚´ ë¦¬í¬íŠ¸ ì¡°íšŒ
        reports = db.collection("sleep_reports")\
            .where("userId", "==", user_id)\
            .where("created_at", ">=", start_date)\
            .stream()
        
        report_list = []
        for doc in reports:
            data = doc.to_dict()
            # created_atì„ datetimeìœ¼ë¡œ ë³€í™˜
            created_at = data.get("created_at")
            if hasattr(created_at, "to_datetime"):
                created_at = created_at.to_datetime()
            elif isinstance(created_at, str):
                created_at = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            data["created_at_dt"] = created_at
            report_list.append(data)
        
        if not report_list:
            return {
                "user_id": user_id,
                "period_days": days,
                "report_count": 0,
                "message": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        # 1. ì „ì²´ í‰ê· 
        total_scores = [r["total_score"] for r in report_list]
        sleep_hours = [r["summary"]["total_duration_hours"] for r in report_list]
        deep_ratios = [r["summary"]["deep_ratio"] for r in report_list]
        rem_ratios = [r["summary"]["rem_ratio"] for r in report_list]
        
        overall_avg = {
            "score": round(sum(total_scores) / len(total_scores), 1),
            "sleep_hours": round(sum(sleep_hours) / len(sleep_hours), 2),
            "deep_ratio": round(sum(deep_ratios) / len(deep_ratios), 1),
            "rem_ratio": round(sum(rem_ratios) / len(rem_ratios), 1)
        }
        
        # 2. ì£¼ì¤‘/ì£¼ë§ ë¹„êµ
        weekday_reports = []
        weekend_reports = []
        
        for report in report_list:
            dt = report["created_at_dt"]
            if dt.weekday() < 5:  # 0=ì›”, 4=ê¸ˆ
                weekday_reports.append(report)
            else:  # 5=í† , 6=ì¼
                weekend_reports.append(report)
        
        weekday_vs_weekend = {}
        
        if weekday_reports:
            weekday_scores = [r["total_score"] for r in weekday_reports]
            weekday_hours = [r["summary"]["total_duration_hours"] for r in weekday_reports]
            weekday_vs_weekend["weekday"] = {
                "count": len(weekday_reports),
                "avg_score": round(sum(weekday_scores) / len(weekday_scores), 1),
                "avg_hours": round(sum(weekday_hours) / len(weekday_hours), 2)
            }
        
        if weekend_reports:
            weekend_scores = [r["total_score"] for r in weekend_reports]
            weekend_hours = [r["summary"]["total_duration_hours"] for r in weekend_reports]
            weekday_vs_weekend["weekend"] = {
                "count": len(weekend_reports),
                "avg_score": round(sum(weekend_scores) / len(weekend_scores), 1),
                "avg_hours": round(sum(weekend_hours) / len(weekend_hours), 2)
            }
        
        # 3. ìš”ì¼ë³„ ë¶„ì„
        weekday_names = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        by_weekday = {}
        
        for i in range(7):
            day_reports = [r for r in report_list if r["created_at_dt"].weekday() == i]
            if day_reports:
                day_scores = [r["total_score"] for r in day_reports]
                day_hours = [r["summary"]["total_duration_hours"] for r in day_reports]
                by_weekday[weekday_names[i]] = {
                    "count": len(day_reports),
                    "avg_score": round(sum(day_scores) / len(day_scores), 1),
                    "avg_hours": round(sum(day_hours) / len(day_hours), 2)
                }
        
        # 4. ì£¼ë³„ íŠ¸ë Œë“œ (ìµœê·¼ 4ì£¼)
        weekly_trends = []
        for week in range(4):
            week_start = datetime.now(timezone.utc) - timedelta(days=(week+1)*7)
            week_end = datetime.now(timezone.utc) - timedelta(days=week*7)
            
            week_reports = [
                r for r in report_list 
                if week_start <= r["created_at_dt"] < week_end
            ]
            
            if week_reports:
                week_scores = [r["total_score"] for r in week_reports]
                weekly_trends.insert(0, {
                    "week": f"{week+1}ì£¼ ì „",
                    "avg_score": round(sum(week_scores) / len(week_scores), 1),
                    "count": len(week_reports)
                })
        
        # 5. ê°œì„  ì¶”ì„¸ ê³„ì‚°
        if len(weekly_trends) >= 2:
            first_week_score = weekly_trends[0]["avg_score"]
            last_week_score = weekly_trends[-1]["avg_score"]
            score_change = last_week_score - first_week_score
            
            if score_change > 5:
                trend = "improving"
                trend_message = f"ì§€ë‚œ 4ì£¼ê°„ {score_change:.1f}ì  ê°œì„ ëì–´ìš”! ğŸ“ˆ"
            elif score_change < -5:
                trend = "declining"
                trend_message = f"ì§€ë‚œ 4ì£¼ê°„ {abs(score_change):.1f}ì  í•˜ë½í–ˆì–´ìš” ğŸ“‰"
            else:
                trend = "stable"
                trend_message = "ì§€ë‚œ 4ì£¼ê°„ ì•ˆì •ì ì…ë‹ˆë‹¤ â¡ï¸"
        else:
            trend = "insufficient_data"
            trend_message = "íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•´ìš”"
        
        # 6. ì¸ì‚¬ì´íŠ¸
        insights = []
        
        # ì£¼ì¤‘/ì£¼ë§ ë¹„êµ
        if "weekday" in weekday_vs_weekend and "weekend" in weekday_vs_weekend:
            weekday_score = weekday_vs_weekend["weekday"]["avg_score"]
            weekend_score = weekday_vs_weekend["weekend"]["avg_score"]
            score_diff = weekend_score - weekday_score
            
            if score_diff > 10:
                insights.append({
                    "type": "info",
                    "message": f"ì£¼ë§ ìˆ˜ë©´ì´ ì£¼ì¤‘ë³´ë‹¤ {score_diff:.0f}ì  ë” ì¢‹ì•„ìš”",
                    "suggestion": "ì£¼ì¤‘ ìˆ˜ë©´ ìŠµê´€ì„ ì£¼ë§ì²˜ëŸ¼ ìœ ì§€í•´ë³´ì„¸ìš”"
                })
            elif score_diff < -10:
                insights.append({
                    "type": "warning",
                    "message": f"ì£¼ë§ ìˆ˜ë©´ì´ ì£¼ì¤‘ë³´ë‹¤ {abs(score_diff):.0f}ì  ë‚®ì•„ìš”",
                    "suggestion": "ì£¼ë§ì—ë„ ê·œì¹™ì ì¸ ìˆ˜ë©´ ì‹œê°„ì„ ìœ ì§€í•˜ì„¸ìš”"
                })
        
        # ìš”ì¼ë³„ íŒ¨í„´
        if by_weekday:
            best_day = max(by_weekday.items(), key=lambda x: x[1]["avg_score"])
            worst_day = min(by_weekday.items(), key=lambda x: x[1]["avg_score"])
            
            insights.append({
                "type": "info",
                "message": f"{best_day[0]}ì´ ê°€ì¥ ì¢‹ì•„ìš” ({best_day[1]['avg_score']}ì )",
                "suggestion": f"{best_day[0]}ì˜ ìŠµê´€ì„ ë‹¤ë¥¸ ìš”ì¼ì—ë„ ì ìš©í•´ë³´ì„¸ìš”"
            })
            
            if worst_day[1]["avg_score"] < 60:
                insights.append({
                    "type": "warning",
                    "message": f"{worst_day[0]}ì´ ê°€ì¥ ë‚˜ë¹ ìš” ({worst_day[1]['avg_score']}ì )",
                    "suggestion": f"{worst_day[0]} ì „ë‚  íŠ¹ë³„íˆ ì£¼ì˜í•˜ì„¸ìš”"
                })
        
        result = {
            "user_id": user_id,
            "period_days": days,
            "report_count": len(report_list),
            "date_range": {
                "start": start_date.isoformat(),
                "end": datetime.now(timezone.utc).isoformat()
            },
            
            "overall_average": overall_avg,
            "weekday_vs_weekend": weekday_vs_weekend,
            "by_weekday": by_weekday,
            "weekly_trends": weekly_trends,
            
            "trend": trend,
            "trend_message": trend_message,
            "insights": insights
        }
        
        print(f"[ì›”ê°„ íŠ¸ë Œë“œ ì™„ë£Œ] {len(report_list)}ê°œ ë¦¬í¬íŠ¸, í‰ê· : {overall_avg['score']:.1f}ì ")
        
        return result
        
    except Exception as e:
        print(f"[ì›”ê°„ íŠ¸ë Œë“œ ì˜¤ë¥˜] {e}")
        raise https_fn.HttpsError("internal", f"Trends calculation failed: {str(e)}")


# ========================================
# âœ¨ Phase 5: ìë™ ë¦¬í¬íŠ¸ ìƒì„±
# ========================================

@https_fn.on_call()
def auto_generate_report(req: https_fn.CallableRequest):
    """
    ì„¸ì…˜ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±
    
    ìš”ì²­ íŒŒë¼ë¯¸í„°:
    - user_id: ì‚¬ìš©ì ID (í•„ìˆ˜)
    - session_id: ì„¸ì…˜ ID (í•„ìˆ˜)
    
    ë°˜í™˜:
    - ìˆ˜ë©´ ì ìˆ˜
    - ì¸ì‚¬ì´íŠ¸
    """
    db = get_db()
    
    user_id = req.data.get("user_id")
    session_id = req.data.get("session_id")
    
    if not user_id or not session_id:
        raise https_fn.HttpsError("invalid-argument", "user_id and session_id are required")
    
    print(f"[ìë™ ë¦¬í¬íŠ¸ ìƒì„±] user: {user_id}, session: {session_id}")
    
    try:
        # 1. ìˆ˜ë©´ ì ìˆ˜ ê³„ì‚°
        score_result = calculate_sleep_score.call({"data": {"session_id": session_id}})
        
        # 2. ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights_result = generate_sleep_insights.call({"data": {"session_id": session_id}})
        
        # 3. í†µí•© ê²°ê³¼
        result = {
            "user_id": user_id,
            "session_id": session_id,
            "score": score_result,
            "insights": insights_result,
            "generated_at": now_utc().isoformat(),
            "auto_generated": True
        }
        
        print(f"[ìë™ ë¦¬í¬íŠ¸ ì™„ë£Œ] session: {session_id}, score: {score_result.get('total_score')}")
        
        return result
        
    except Exception as e:
        print(f"[ìë™ ë¦¬í¬íŠ¸ ì˜¤ë¥˜] {e}")
        raise https_fn.HttpsError("internal", f"Auto report generation failed: {str(e)}")


# ========================================
# âœ¨ Phase 5: ì„¸ì…˜ ì¢…ë£Œ ê°ì§€ (íŠ¸ë¦¬ê±°)
# ========================================

@firestore_fn.on_document_updated(document="session_state/{stateId}", region="asia-northeast3")
def on_session_end(event: firestore_fn.Event[firestore_fn.Change[firestore_fn.DocumentSnapshot | None]]):
    """
    ì„¸ì…˜ ìƒíƒœ ë³€ê²½ ê°ì§€ â†’ ì¢…ë£Œ ì‹œ ìë™ ë¦¬í¬íŠ¸ ìƒì„±
    """
    db = get_db()
    
    if event.data is None:
        return
    
    before = event.data.before
    after = event.data.after
    
    if before is None or after is None:
        return
    
    before_data = before.to_dict() or {}
    after_data = after.to_dict() or {}
    
    # ì„¸ì…˜ì´ í™œì„± â†’ ì¢…ë£Œë¡œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
    # (ì˜ˆ: stageê°€ "Awake"ê°€ 30ë¶„ ì´ìƒ ì§€ì†ë˜ë©´ ì¢…ë£Œë¡œ ê°„ì£¼)
    
    before_stage = before_data.get("stage")
    after_stage = after_data.get("stage")
    
    # ì˜ˆì‹œ: Awake ìƒíƒœë¡œ ë³€ê²½ë˜ê³  ì¶©ë¶„í•œ ì‹œê°„ì´ ì§€ë‚¬ë‹¤ë©´
    if after_stage == "Awake":
        last_change = after_data.get("last_change_ts")
        if hasattr(last_change, "to_datetime"):
            last_change = last_change.to_datetime()
        
        now = now_utc()
        
        # 30ë¶„ ì´ìƒ Awake ìƒíƒœë©´ ì„¸ì…˜ ì¢…ë£Œë¡œ ê°„ì£¼
        if last_change and (now - last_change).total_seconds() > 1800:  # 30ë¶„
            user_id = after_data.get("userId")
            session_id = after_data.get("sessionId")
            
            # ì´ë¯¸ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
            report_exists = db.collection("sleep_reports").document(session_id).get().exists
            
            if not report_exists:
                print(f"[ì„¸ì…˜ ì¢…ë£Œ ê°ì§€] user: {user_id}, session: {session_id}")
                
                try:
                    # ìë™ ë¦¬í¬íŠ¸ ìƒì„± (ë‚´ë¶€ í˜¸ì¶œ)
                    # ì‹¤ì œë¡œëŠ” Cloud Tasksë¡œ ë¹„ë™ê¸° ì²˜ë¦¬í•˜ëŠ” ê²Œ ì¢‹ìŒ
                    print(f"[ìë™ ë¦¬í¬íŠ¸ íŠ¸ë¦¬ê±°] session: {session_id}")
                    # ì—¬ê¸°ì„œëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³ , ì‹¤ì œ ìƒì„±ì€ í”„ë¡ íŠ¸ì—”ë“œê°€ í˜¸ì¶œí•˜ë„ë¡
                    
                except Exception as e:
                    print(f"[ìë™ ë¦¬í¬íŠ¸ íŠ¸ë¦¬ê±° ì˜¤ë¥˜] {e}")